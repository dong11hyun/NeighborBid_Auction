# 📘 설계문서 4: 대용량 데이터 처리 분석 및 리소스 계획

> **주요 질문**: 1억 건 데이터, 2만 건 크롤링, OpenSearch 운영이 단일 EC2에서 가능한가?

---

## 1. 프로젝트별 데이터 요구사항 정리

| 프로젝트 | 데이터 규모 | 저장소 | 특징 |
|----------|------------|--------|------|
| **Logisflow** | 1억 건 | PostgreSQL | 대용량 조회/분석 필요 |
| **크롤링 프로젝트** | 2만 건 | PostgreSQL | 수집 후 OpenSearch 연동 |
| **OpenSearch 프로젝트** | 2만 건 | OpenSearch | 검색/분석 엔진 |
| **라디어스** | 3,000 행 | PostgreSQL | 소규모, 문제없음 |

---

## 2. 데이터 용량 계산

### 📊 Logisflow: 1억 건

```
가정: 1레코드 평균 500 바이트 (일반적인 물류 데이터)

순수 데이터:   100,000,000 × 500B = 약 50GB
인덱스 추가:   50GB × 1.3 = 약 65GB
안전 마진:     65GB × 1.2 = 약 78GB

→ PostgreSQL 데이터만 최소 80GB 스토리지 필요
```

### 📊 OpenSearch: 2만 건

```
가정: 1문서 평균 2KB (텍스트 포함)

순수 데이터:   20,000 × 2KB = 약 40MB
인덱스 포함:   40MB × 2 = 약 80MB
실제 운영:     약 200MB 예상 (여유 포함)

→ 2만 건은 OpenSearch에서 매우 작은 규모 ✅
```

### 📊 크롤링 + 라디어스

```
크롤링 2만 건: 약 100MB
라디어스 3천 행: 약 5MB

→ 전혀 문제없는 규모 ✅
```

---

## 3. 💡 핵심 질문: 1억 건이 진짜 필요한가?

> [!IMPORTANT]
> **포트폴리오 목적**이라면 **실제 1억 건을 저장할 필요가 없습니다!**

### 포트폴리오에서 증명해야 할 것

| 증명 포인트 | 필요한 것 | 실제 필요 데이터 |
|------------|----------|-----------------|
| "1억 건 처리 가능" | 아키텍처 설계 문서 | 0건 |
| "대용량 쿼리 최적화" | 파티셔닝, 인덱싱 코드 | 10만~100만 건 |
| "성능 테스트 결과" | 부하 테스트 (k6 등) | 10만 건 충분 |
| "확장 가능 구조" | 샤딩/레플리카 설계 | 설계 문서 |

### ⭐ 권장 전략: "샘플 데이터 + 확장 설계"

```
실제 저장:     10만 ~ 100만 건 (시연용)
문서로 증명:   "1억 건 대응 가능한 파티셔닝/인덱싱 적용"
부하 테스트:   "100만 건 기준 응답시간 XXms"
```

---

## 4. 시나리오별 EC2 사양 분석

### 시나리오 A: 샘플 데이터 (100만 건) - ⭐ 권장

| 항목 | 요구량 | 설명 |
|------|--------|------|
| RAM | 8GB | PostgreSQL 2GB + OpenSearch 2GB + 앱 4GB |
| Storage | 50GB | 충분한 여유 |
| CPU | 2 vCPU | 일반 조회 충분 |
| **인스턴스** | **t3.large** | **월 ~$60** |

### 시나리오 B: 실제 1억 건 저장 - ⚠️ 비현실적

| 항목 | 요구량 | 설명 |
|------|--------|------|
| RAM | 32GB+ | PostgreSQL만 16GB+ 필요 |
| Storage | 200GB+ | 데이터 + 인덱스 + 백업 |
| CPU | 8 vCPU+ | 대용량 쿼리 처리 |
| **인스턴스** | **r6i.xlarge 이상** | **월 $200+** |

> [!WARNING]
> 1억 건을 실제 저장하면 **월 비용 4배 이상** 증가하고, 포트폴리오 가치는 크게 다르지 않습니다.

---

## 5. ⭐ 최종 권장 구성

### 인스턴스 사양

```
┌─────────────────────────────────────────────────────────┐
│              권장: t3.large (또는 t3.xlarge)              │
├─────────────────────────────────────────────────────────┤
│  vCPU: 2 (large) / 4 (xlarge)                           │
│  RAM:  8GB (large) / 16GB (xlarge)                      │
│  Storage: 100GB gp3 (IOPS 3000)                         │
│  예상 비용: $60~100/월                                   │
└─────────────────────────────────────────────────────────┘
```

### 메모리 할당 계획 (8GB 기준)

```
┌─────────────────────────────────────────────────────────┐
│                    메모리 할당 (8GB)                      │
├──────────────────────┬──────────────────────────────────┤
│ 서비스               │ 할당량                            │
├──────────────────────┼──────────────────────────────────┤
│ OS + 시스템          │ 1GB                               │
│ Nginx                │ 128MB                             │
│ PostgreSQL (공유)    │ 2GB (shared_buffers)             │
│ OpenSearch           │ 1.5GB (-Xmx1536m)                │
│ Django/FastAPI 앱 ×5 │ 각 300MB = 1.5GB                 │
│ Redis (선택)         │ 256MB                             │
│ Kafka (필요시)       │ 1GB                               │
│ 여유                 │ 0.5GB                             │
├──────────────────────┼──────────────────────────────────┤
│ 합계                 │ 약 8GB                            │
└──────────────────────┴──────────────────────────────────┘
```

> [!TIP]
> Kafka 사용 시 **t3.xlarge (16GB)** 권장

---

## 6. 대용량 처리를 위한 PostgreSQL 최적화

### 파티셔닝 (1억 건 대응)

```sql
-- 월별 파티셔닝 예시 (Logisflow)
CREATE TABLE logistics_data (
    id BIGSERIAL,
    created_at TIMESTAMP NOT NULL,
    shipment_data JSONB,
    ...
) PARTITION BY RANGE (created_at);

-- 월별 파티션 생성
CREATE TABLE logistics_data_2025_01 
    PARTITION OF logistics_data
    FOR VALUES FROM ('2025-01-01') TO ('2025-02-01');

CREATE TABLE logistics_data_2025_02 
    PARTITION OF logistics_data
    FOR VALUES FROM ('2025-02-01') TO ('2025-03-01');
```

### 인덱스 전략

```sql
-- 복합 인덱스 (자주 조회되는 컬럼)
CREATE INDEX CONCURRENTLY idx_logistics_status_date 
ON logistics_data (status, created_at DESC);

-- 부분 인덱스 (활성 데이터만)
CREATE INDEX idx_active_shipments 
ON logistics_data (shipment_id) 
WHERE status = 'active';
```

### PostgreSQL 설정 최적화 (`postgresql.conf`)

```ini
# 메모리 설정 (2GB 할당 기준)
shared_buffers = 512MB
effective_cache_size = 1536MB
work_mem = 32MB
maintenance_work_mem = 256MB

# 쿼리 최적화
random_page_cost = 1.1  # SSD 사용 시
effective_io_concurrency = 200
```

---

## 7. 프로젝트별 Docker 메모리 제한

### docker-compose.yml 예시

```yaml
services:
  app:
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  db:
    deploy:
      resources:
        limits:
          memory: 2G

  opensearch:
    environment:
      - "OPENSEARCH_JAVA_OPTS=-Xms768m -Xmx768m"
    deploy:
      resources:
        limits:
          memory: 1536M
```

---

## 8. ✅ 결론: 가능 여부

| 질문 | 답변 |
|------|------|
| 2만 건 크롤링 + OpenSearch | ✅ **전혀 문제없음** |
| 3천 행 라디어스 | ✅ **전혀 문제없음** |
| 1억 건 Logisflow (실제 저장) | ⚠️ **비용 대비 효율 낮음** |
| 1억 건 대응 설계 + 샘플 데이터 | ✅ **이 방식 강력 권장** |

### 🎯 최종 권장

```
1. EC2 t3.large (8GB) 또는 t3.xlarge (16GB) 선택
2. 스토리지 100GB gp3 설정
3. Logisflow는 10만~100만 건 샘플 데이터 + 파티셔닝 설계 문서로 증명
4. README에 "1억 건 대응 가능한 아키텍처" 설계 내용 포함
5. 부하 테스트 결과로 성능 증명 (k6 등 사용)
```

---

## 9. 포트폴리오 어필 포인트

### README에 들어갈 내용

```markdown
## 🔧 대용량 데이터 처리 아키텍처

### 확장성 설계
- PostgreSQL 테이블 파티셔닝으로 **1억 건 이상** 대응 가능
- 월별 파티션 자동 생성 스크립트 구현
- 복합 인덱스 및 부분 인덱스 최적화

### 성능 테스트 결과 (100만 건 기준)
| 쿼리 유형 | 응답 시간 |
|----------|----------|
| 단순 조회 | 15ms |
| 집계 쿼리 | 120ms |
| 전문 검색 | 45ms |

### 스케일 아웃 전략
- 읽기 전용 레플리카 추가 가능
- AWS RDS로 마이그레이션 시 자동 백업/장애 복구
```

> [!TIP]
> 면접에서 "왜 실제 1억 건을 넣지 않았나요?" 질문이 오면:
> "비용 대비 증명 가치가 동일하고, 설계와 최적화 역량을 보여드리는 것이 목적이었습니다"라고 답변!
